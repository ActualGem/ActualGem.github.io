---
title: 'Optimizing an STDP Learning Engine for FPGAs'
date: 2025-06-26
permalink: /posts/2025/06/optimizing-an-stdp-learning-engine-for-fpgas/
tags:
  - FPGAS
  - Spiking Neural Networks
  - STDP
---

Written by Aaryan Dhawan, in collaboration with Muhammad Farhan Azmine

What is STDP?
---------
Spike-Timing-Dependent Plasticity (STDP) is a biological learning rule that adjusts the strength of connections between neurons based on the relative timing of their spikes. In simple terms, if neuron A fires just before neuron B, the connection between them is strengthened. Conversely, if neuron A fires after neuron B, the connection is weakened. In machine learning, STDP is used to train Spiking Neural Networks (SNNs) by mimicking this biological process, allowing the network to learn from temporal patterns in data. 
Using temporal patterns to learn, STDP allows SNNs to process information similarly to the human brain, making them suitable for tasks like real-time learning, robotics, and in edge computing.

On-Chip STDP Learning 
========
On-chip STDP learning refers to the implementation of the STDP learning algorithm directly within a hardware implementation of a SNN, rather than training the network in software and transferring it to hardware. Implementing the learning algorithm can reduce the need for large datasets, as the network can learn from the data it processes in real-time. This approach is particularly beneficial for applications with limited data availability or when power consumption is a concern. In 2019, researches at Texas A&M University developed FPGA efficient, STDP based SNN models for both supervised and unsupervised learning [1](https://dl.acm.org/doi/10.1145/3313866) with Liquid State machines (LSMs). In this work, they build a STDP learning engine that takes the spike timing difference between the reservoir neurons and the output neurons, and uses that to determine between strengthening (Potentiation) or weakening (Depression) the connection between the two neurons. This adjustment value is determine by the following equations:
$$\Delta w = \begin{cases}
\eta_{+} \cdot e^{-\frac{t_{pre}-t_{post}}{\tau_{+}}} & \text{if } t_{pre} < t_{post} \\
-\eta_{-} \cdot e^{-\frac{t_{post}-t_{pre}}{\tau_{-}}} & \text{if } t_{pre} > t_{post}
\end{cases}$$

where:
- $$\Delta w$$ is the change in weight
- $$t_{pre}$$ is the time of the pre-synaptic spike
- $$t_{post}$$ is the time of the post-synaptic spike
- $$\tau_{+}$$ is the time constant for potentiation
- $$\tau_{-}$$ is the time constant for depression
- $$\eta_{+}$$ is the amplitude of the potentiation curve
- $$\eta_{-}$$ is the amplitude of the depression curve

Over a given sample period, the neurons will produce spike trains, which are compared to each other to compute a timing difference value. This timing difference is used to calculate the potentiation or depression value, strengthening or weakening a given connection. Determining potentiation vs depression can be visualized as follows:
![STDP Simulation](/images/STDP_learning.gif)
Spiking before the post-synaptic neuron results in a positive timing difference, leading to potentiation, while spiking after results in a negative timing difference, leading to depression.

Original Hardware Design
========
In [1](https://dl.acm.org/doi/10.1145/3313866), the authors develop a "hardware-friendly STDP learning engine", recreated in the following image.
<insert image here>
Discrete spike trains from the reservoir neurons and output neurons are fed into Serial-In/Parallel-Out (SIPO) shift registers, the "length" of the registers are equal to the number of timesteps in a given sample period (For HW, a fixed sample period). The shift registers corresponding to the reservior neurons are then selected by an M to 1 multiplexer, where M is the number of reservoir neurons. Once the shift register is selected and its data is passed through the multiplexer, the two spike trains, 1 post-synaptic and 1 pre-synaptic, are compared to each other to determine the timing difference to adjust that given weight. This is done by comparator, which looks as the Most Significant bit(MSB) of the two spike trains and looks at which of the two is high/Logic-1. If the Pre-synaptic neuron MSB is high, then the timing difference will be negative and the post-synaptic spike train will be sent to negative priority encoder; If the Post-synaptic neuron MSB is high, then the timing difference will be positive and the pre-synaptic spike train will be sent to positive priority encoder. 